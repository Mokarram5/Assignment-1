{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a75803d-37c6-4835-b589-5e02e827578e",
   "metadata": {},
   "source": [
    "# Assignment - Na√Øve bayes-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaa6d8c-e5c0-4e2c-bbbc-52d65df8489c",
   "metadata": {},
   "source": [
    "#### Q1. What is Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57578384-d44c-4a8f-b55f-51599be4790c",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f2b076-57e1-4536-aab0-e4976880471c",
   "metadata": {},
   "source": [
    "Bayes' theorem is a fundamental concept in probability theory that describes the probability of an event based on prior knowledge of conditions that might be related to the event. It is named after the Reverend Thomas Bayes, who introduced the theorem.\n",
    "\n",
    "In short, Bayes' theorem is expressed as:\n",
    "\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\]\n",
    "\n",
    "Here's a brief explanation of the terms:\n",
    "\n",
    "- \\( P(A|B) \\): The probability of event \\(A\\) occurring given that event \\(B\\) has occurred.\n",
    "- \\( P(B|A) \\): The probability of event \\(B\\) occurring given that event \\(A\\) has occurred.\n",
    "- \\( P(A) \\) and \\( P(B) \\): The probabilities of events \\(A\\) and \\(B\\) occurring independently.\n",
    "\n",
    "Bayes' theorem is commonly used in statistics, machine learning, and various fields to update probabilities based on new evidence or information. It provides a formal framework for incorporating prior knowledge and updating beliefs in light of new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2039d588-50b7-48c8-8c1a-bfa53aedc298",
   "metadata": {},
   "source": [
    "#### Q2. What is the formula for Bayes' theorem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25802504-c738-48e2-9b10-d05a451e8075",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c05e141-792a-48a4-b3fd-8360f1838ec0",
   "metadata": {},
   "source": [
    "Bayes' theorem is expressed mathematically as:\r\n",
    "\r\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\]\r\n",
    "\r\n",
    "Here's a breakdown of the terms in the formula:\r\n",
    "\r\n",
    "- \\( P(A|B) \\): The probability of event \\(A\\) occurring given that event \\(B\\) has occurred.\r\n",
    "- \\( P(B|A) \\): The probability of event \\(B\\) occurring given that event \\(A\\) has occurred.\r\n",
    "- \\( P(A) \\): The prior probability of event \\(A\\), i.e., the probability of \\(A\\) occurring independently of \\(B\\).\r\n",
    "- \\( P(B) \\): The prior probability of event \\(B\\), i.e., the probability of \\(B\\) occurring independently of \\(A\\).\r\n",
    "\r\n",
    "In words, Bayes' theorem provides a way to update the probability of an event (\\(A\\)) based on new evidence or information (\\(B\\)). It is a fundamental concept in probability theory and is widely used in various fields, including statistics, machine learning, and Bayesian inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9221c46c-4c7a-44f0-a9cb-a64bd7c8f08a",
   "metadata": {},
   "source": [
    "#### Q3. How is Bayes' theorem used in practice?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae4c286-ca90-4c5e-b8ac-3dd7b72cc207",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138bac4c-27cb-4583-918f-7febc0be2ca0",
   "metadata": {},
   "source": [
    "Bayes' theorem is used in practice in various fields and applications to update probabilities based on new evidence or information. Here are some specific examples of how Bayes' theorem is applied:\r\n",
    "\r\n",
    "1. **Medical Diagnosis:**\r\n",
    "   - In medical diagnosis, Bayes' theorem is used to update the probability of a patient having a particular disease based on the results of diagnostic tests. It helps incorporate test sensitivity and specificity to improve the accuracy of diagnoses.\r\n",
    "\r\n",
    "2. **Spam Filtering:**\r\n",
    "   - Bayesian spam filters use Bayes' theorem to classify emails as spam or not spam. The theorem helps update the probability of an email being spam given the occurrence of certain words or features in the email content.\r\n",
    "\r\n",
    "3. **Document Classification:**\r\n",
    "   - In natural language processing and document classification, Bayes' theorem is applied to categorize documents into different classes. For example, it can be used to classify news articles into topics based on their content.\r\n",
    "\r\n",
    "4. **A/B Testing:**\r\n",
    "   - Bayes' theorem is used in A/B testing scenarios to update the probability of one version of a product or website being more effective than another. It helps make informed decisions about which design or feature is more likely to lead to a desired outcome.\r\n",
    "\r\n",
    "5. **Fault Detection in Engineering:**\r\n",
    "   - In engineering and system diagnostics, Bayes' theorem is employed for fault detection. It helps update the probability of a specific fault given observed sensor readings or system behaviors.\r\n",
    "\r\n",
    "6. **Finance and Risk Management:**\r\n",
    "   - In finance, Bayes' theorem is used for risk assessment and portfolio management. It helps update the probability of market events or changes in asset values based on new economic indicators or market trends.\r\n",
    "\r\n",
    "7. **Weather Forecasting:**\r\n",
    "   - Meteorologists use Bayes' theorem in Bayesian forecasting to update the probability of weather conditions based on real-time observations. It allows for more accurate and dynamically adjusted weather predictions.\r\n",
    "\r\n",
    "8. **Machine Learning:**\r\n",
    "   - In machine learning, especially Bayesian methods, Bayes' theorem is used for classification and probabilistic modeling. It helps update the probability of a data point belonging to a certain class based on observed features.\r\n",
    "\r\n",
    "9. **Quality Control and Manufacturing:**\r\n",
    "   - Bayes' theorem is applied in quality control to update the probability of a manufacturing process producing defective products. It helps make decisions about process adjustments to improve product quality.\r\n",
    "\r\n",
    "10. **Epidemiology and Public Health:**\r\n",
    "    - In epidemiological studies, Bayes' theorem is used to update the probability of disease outbreaks or the effectiveness of interventions based on new data and surveillance information.\r\n",
    "\r\n",
    "In essence, Bayes' theorem provides a principled and systematic way to update beliefs or probabilities as new evidence becomes available. Its applications are diverse and extend across fields where probabilistic reasoning and updating are essential for making informed decisions.ed model complexity.m."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e506f36b-ec4b-4131-97bd-a2529494878f",
   "metadata": {},
   "source": [
    "#### Q4. What is the relationship between Bayes' theorem and conditional probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e31682-51b7-4ce7-98f0-5190cceb24fd",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc9709b-71f6-446f-a76b-3f440ae34024",
   "metadata": {},
   "source": [
    "Bayes' theorem is intimately connected to conditional probability, as it provides a way to compute conditional probabilities in situations where some information is known. Let's explore the relationship between Bayes' theorem and conditional probability.\r\n",
    "\r\n",
    "**Conditional Probability:**\r\n",
    "Conditional probability is the probability of an event occurring given that another event has already occurred. It is denoted by \\( P(A|B) \\), which reads \"the probability of event A given event B.\"\r\n",
    "\r\n",
    "Mathematically, conditional probability is calculated using the formula:\r\n",
    "\r\n",
    "\\[ P(A|B) = \\frac{P(A \\cap B)}{P(B)} \\]\r\n",
    "\r\n",
    "where:\r\n",
    "- \\( P(A \\cap B) \\) is the probability of both events A and B occurring (the intersection of A and B).\r\n",
    "- \\( P(B) \\) is the probability of event B occurring.\r\n",
    "\r\n",
    "**Bayes' Theorem:**\r\n",
    "Bayes' theorem provides a way to reverse the conditioning, allowing us to find the probability of an initial event given new information. It is expressed as:\r\n",
    "\r\n",
    "\\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\]\r\n",
    "\r\n",
    "where:\r\n",
    "- \\( P(A|B) \\) is the conditional probability of A given B.\r\n",
    "- \\( P(B|A) \\) is the conditional probability of B given A.\r\n",
    "- \\( P(A) \\) and \\( P(B) \\) are the probabilities of events A and B, respectively.\r\n",
    "\r\n",
    "**Relationship:**\r\n",
    "The relationship between Bayes' theorem and conditional probability is evident in the formula itself. Bayes' theorem is essentially a formula for calculating conditional probability in situations where calculating \\( P(A|B) \\) directly might be challenging, but \\( P(B|A) \\) is known.\r\n",
    "\r\n",
    "Here's a breakdown of the relationship:\r\n",
    "1. **Starting Point:** Conditional probability \\( P(A|B) \\) is the starting point, expressing the probability of A given B.\r\n",
    "2. **Bayes' Theorem:** Bayes' theorem provides a way to express \\( P(A|B) \\) in terms of \\( P(B|A) \\), \\( P(A) \\), and \\( P(B) \\). It's a method to update beliefs based on new evidence or information.\r\n",
    "\r\n",
    "In summary, Bayes' theorem extends the concept of conditional probability by providing a systematic and formal way to update probabilities when new evidence becomes available. It allows for reasoning about uncertainty and updating beliefs in a principled manner.ew, unseen data. make the SVM robust to outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667b7061-25cf-43b3-9e72-068ce75b5602",
   "metadata": {},
   "source": [
    "#### Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20cd730-89b7-4244-bc2f-d635a4a2e36e",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee35b628-d76a-4da6-9d6a-028ea3a5276e",
   "metadata": {},
   "source": [
    "Choosing the appropriate type of Naive Bayes classifier for a given problem depends on the nature of the data and the assumptions that can be reasonably made about the independence of features. The three main types of Naive Bayes classifiers are:\n",
    "\n",
    "1. **Gaussian Naive Bayes:**\n",
    "   - **Applicability:** Suitable for continuous data that follows a Gaussian (normal) distribution.\n",
    "   - **Assumption:** Assumes that the features are normally distributed within each class.\n",
    "   - **Example:** Often used in problems where features are real-valued and have a bell-shaped distribution.\n",
    "\n",
    "```python\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "classifier = GaussianNB()\n",
    "```\n",
    "\n",
    "2. **Multinomial Naive Bayes:**\n",
    "   - **Applicability:** Typically used for discrete data, such as text data represented as word counts.\n",
    "   - **Assumption:** Assumes that features are counts or frequencies.\n",
    "   - **Example:** Commonly used in text classification tasks, such as spam detection or topic classification.\n",
    "\n",
    "```python\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "```\n",
    "\n",
    "3. **Bernoulli Naive Bayes:**\n",
    "   - **Applicability:** Suitable for binary or boolean features.\n",
    "   - **Assumption:** Assumes that features are binary variables (0 or 1).\n",
    "   - **Example:** Often used in problems where the features are binary, such as document classification based on the presence or absence of words.\n",
    "\n",
    "```python\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "classifier = BernoulliNB()\n",
    "```\n",
    "\n",
    "**How to Choose:**\n",
    "1. **Nature of Features:**\n",
    "   - **Continuous Features:** If your features are continuous and approximately normally distributed, consider Gaussian Naive Bayes.\n",
    "   - **Discrete Features:** For discrete features, especially when dealing with text data, Multinomial or Bernoulli Naive Bayes might be more appropriate.\n",
    "\n",
    "2. **Data Distribution:**\n",
    "   - **Distribution Assumption:** Consider the distribution assumption of each type and choose the one that aligns with your data. Gaussian Naive Bayes assumes normal distribution, while Multinomial and Bernoulli Naive Bayes are suitable for count or binary data.\n",
    "\n",
    "3. **Size of Dataset:**\n",
    "   - **Small Dataset:** For small datasets or when features are not well-modeled by a normal or multinomial distribution, Naive Bayes classifiers might still perform well.\n",
    "\n",
    "4. **Empirical Testing:**\n",
    "   - **Cross-Validation:** Empirically test the performance of different Naive Bayes classifiers using cross-validation on your dataset.\n",
    "   - **Compare Results:** Compare results in terms of accuracy, precision, recall, and F1-score to choose the most effective classifier for your problem.\n",
    "\n",
    "It's important to note that despite the \"naive\" assumption of independence among features, Naive Bayes classifiers often perform surprisingly well in practice, especially for text classification tasks. Experimenting with different types and assessing their performance on your specific problem is a practical approach to choosing the right Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb836384-c0ed-4548-b846-536f44b6d341",
   "metadata": {},
   "source": [
    "#### Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff8c62b-d719-4a12-b291-871c6dfd8096",
   "metadata": {},
   "source": [
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d5263e-2540-4819-8fb5-3f83b7bdfc1e",
   "metadata": {},
   "source": [
    "#### Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72ddb98-2ef1-47a8-a12b-07812e4538ba",
   "metadata": {},
   "source": [
    "\n",
    "To predict the class using Naive Bayes, we'll use the following steps:\r\n",
    "\r\n",
    "Calculate Prior Probabilities:\r\n",
    "\r\n",
    "Given equal prior probabilities for each class, \r\n",
    "ÔøΩ\r\n",
    "(\r\n",
    "ÔøΩ\r\n",
    ")\r\n",
    "P(A) and \r\n",
    "ÔøΩ\r\n",
    "(\r\n",
    "ÔøΩ\r\n",
    ")\r\n",
    "P(B) are both 0.5.\r\n",
    "Calculate Class-Conditional Probabilities (Likelihoods):\r\n",
    "\r\n",
    "For each class and each feature value, calculate the class-conditional probability \r\n",
    "ÔøΩ\r\n",
    "(\r\n",
    "ÔøΩ\r\n",
    "ÔøΩ\r\n",
    "‚à£\r\n",
    "ÔøΩ\r\n",
    ")\r\n",
    "P(X \r\n",
    "i\r\n",
    "‚Äã\r\n",
    " ‚à£A) and \r\n",
    "ÔøΩ\r\n",
    "(\r\n",
    "ÔøΩ\r\n",
    "ÔøΩ\r\n",
    "‚à£\r\n",
    "ÔøΩ\r\n",
    ")\r\n",
    "P(X \r\n",
    "i\r\n",
    "‚Äã\r\n",
    " ‚à£B).\r\n",
    "Calculate Posterior Probabilities:\r\n",
    "\r\n",
    "Use Bayes' theorem to calculate the posterior probabilities for each class given the new feature values (X1=3 and X2=4).\r\n",
    "Make Prediction:\r\n",
    "\r\n",
    "Choose the class with the highest posterior probability as the predicted class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dea131d-a88b-46ec-a023-bb42b71c8498",
   "metadata": {},
   "source": [
    "Prior Probabilities:\n",
    "P(A) = P(B) = 0.5\n",
    "\n",
    "Class-Conditional Probabilities (Likelihoods):\n",
    "P(X1=3|A) = 4/10 = 0.4\n",
    "P(X1=3|B) = 1/5 = 0.2\n",
    "P(X2=4|A) = 3/10 = 0.3\n",
    "P(X2=4|B) = 3/5 = 0.6\n",
    "\n",
    "Posterior Probabilities (using Bayes' theorem):\n",
    "P(A|X1=3, X2=4) = P(X1=3|A) * P(X2=4|A) * P(A) = 0.4 * 0.3 * 0.5 = 0.06\n",
    "P(B|X1=3, X2=4) = P(X1=3|B) * P(X2=4|B) * P(B) = 0.2 * 0.6 * 0.5 = 0.06\n",
    "\n",
    "Normalization:\n",
    "Normalize the probabilities to sum to 1.\n",
    "P(A|X1=3, X2=4) / (P(A|X1=3, X2=4) + P(B|X1=3, X2=4)) = 0.06 / (0.06 + 0.06) = 0.5\n",
    "P(B|X1=3, X2=4) / (P(A|X1=3, X2=4) + P(B|X1=3, X2=4)) = 0.5\n",
    "\n",
    "Prediction:\n",
    "Since both classes have equal posterior probabilities, the Naive Bayes classifier would predict either class A or class B for the new instance with features X1=3 and X2=4.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
